import os
import re
import json
import markdown
from bs4 import BeautifulSoup
from datetime import datetime

def load_template(template_path):
    """åŠ è½½HTMLæ¨¡æ¿"""
    with open(template_path, 'r', encoding='utf-8') as f:
        return f.read()

def extract_metadata(md_content):
    """ä»Markdownå†…å®¹ä¸­æå–å…ƒæ•°æ®"""
    metadata = {
        'title': '',
        'date': '',
        'category': '',
        'readingTime': '',
        'excerpt': ''
    }
    
    lines = md_content.split('\n')
    if lines and lines[0].strip() == '---':
        meta_end = -1
        for i, line in enumerate(lines[1:], 1):
            if line.strip() == '---':
                meta_end = i
                break
        
        if meta_end > 0:
            meta_lines = lines[1:meta_end]
            for line in meta_lines:
                if ':' in line:
                    key, value = [x.strip() for x in line.split(':', 1)]
                    key = key.lower()
                    
                    # å¤„ç†å¸¦å¼•å·çš„å€¼
                    if value.startswith('"') and value.endswith('"'):
                        value = value[1:-1]
                    
                    if key == 'readingtime':  # ç¡®ä¿æ­£ç¡®å¤„ç†readingTime
                        key = 'readingTime'
                    
                    metadata[key] = value
            
            return metadata, '\n'.join(lines[meta_end + 1:])
    
    return metadata, md_content

def convert_md_to_html(md_path, output_dir='inner_blogs'):
    """å°†Markdownæ–‡ä»¶è½¬æ¢ä¸ºHTML"""
    with open(md_path, 'r', encoding='utf-8') as f:
        md_content = f.read()
    
    metadata, content = extract_metadata(md_content)
    
    # ä½¿ç”¨æ–‡ä»¶åä½œä¸ºæ ‡é¢˜çš„åå¤‡é€‰é¡¹
    if not metadata['title']:
        metadata['title'] = os.path.splitext(os.path.basename(md_path))[0]
    
    # ä½¿ç”¨å½“å‰æ—¥æœŸä½œä¸ºåå¤‡é€‰é¡¹
    if not metadata['date']:
        metadata['date'] = datetime.now().strftime('%Y-%m-%d')
    
    # è®¾ç½®é»˜è®¤å€¼
    if not metadata['readingTime']:
        metadata['readingTime'] = '5åˆ†é’Ÿ'
    if not metadata['category']:
        metadata['category'] = 'æœªåˆ†ç±»'
    if not metadata['excerpt']:
        # ä»å†…å®¹ä¸­æå–ç¬¬ä¸€æ®µä½œä¸ºæ‘˜è¦
        first_para = content.split('\n\n')[0]
        # ç§»é™¤Markdownæ ‡è®°
        excerpt = re.sub(r'#+ |`|_|\*|\[|\]|\(|\)', '', first_para)
        metadata['excerpt'] = excerpt[:200] + '...' if len(excerpt) > 200 else excerpt
    
    # è½¬æ¢Markdownä¸ºHTML
    html_content = markdown.markdown(
        content,
        extensions=[
            'markdown.extensions.fenced_code',
            'markdown.extensions.tables',
            'markdown.extensions.toc',
            'markdown.extensions.meta'
        ]
    )
    
    template = load_template('inner_components/article_template.html')
    html_output = template.replace('{{title}}', metadata['title'])\
                         .replace('{{date}}', metadata['date'])\
                         .replace('{{category}}', metadata['category'])\
                         .replace('{{readingTime}}', metadata['readingTime'])\
                         .replace('{{excerpt}}', metadata['excerpt'])\
                         .replace('{{content}}', html_content)
    
    os.makedirs(output_dir, exist_ok=True)
    output_filename = os.path.splitext(os.path.basename(md_path))[0] + '.html'
    output_path = os.path.join(output_dir, output_filename)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(html_output)
    
    return metadata

def update_featured_posts(posts_metadata):
    """æ›´æ–°é¦–é¡µçš„ç²¾é€‰æ–‡ç« åˆ—è¡¨"""
    # æŒ‰æ—¥æœŸæ’åº
    sorted_posts = sorted(posts_metadata, key=lambda x: x['date'], reverse=True)
    
    featured_posts = {
        "posts": []
    }
    
    for post in sorted_posts:
        featured_post = {
            'title': post['title'],
            'url': f'inner_blogs/{os.path.splitext(post["filename"])[0]}.html',
            'date': post['date'],
            'excerpt': post['excerpt'],
            'category': post['category'],
            'readingTime': post.get('readingTime', '5åˆ†é’Ÿ')  # ç¡®ä¿è·å–readingTime
        }
        featured_posts['posts'].append(featured_post)
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs('inner_js', exist_ok=True)
    
    # ä¿å­˜ä¸ºJSONï¼ŒæŒ‰æ—¥æœŸå€’åºæ’åº
    with open('inner_js/featured_posts.json', 'w', encoding='utf-8') as f:
        json.dump(featured_posts, f, ensure_ascii=False, indent=2)

def update_sidebar(posts_metadata):
    """æ›´æ–°ä¾§è¾¹æ çš„æ–‡ç« åˆ—è¡¨"""
    sorted_posts = sorted(posts_metadata, key=lambda x: x['date'], reverse=True)
    
    posts_html = ''
    for post in sorted_posts:
        posts_html += f'''
        <li>
            <a href="/inner_blogs/{os.path.splitext(post['filename'])[0]}.html">
                <div class="post-info">
                    <span class="post-title">{post['title']}</span>
                    <div class="post-meta">
                        <span class="post-date">ğŸ“… {post['date']}</span>
                        <span class="post-category">ğŸ“‘ {post['category']}</span>
                        <span class="post-reading-time">â±ï¸ {post['readingTime']}</span>
                    </div>
                </div>
            </a>
        </li>
        '''
    
    sidebar_path = 'inner_components/sidebar.html'
    with open(sidebar_path, 'r', encoding='utf-8') as f:
        sidebar_content = f.read()
    
    soup = BeautifulSoup(sidebar_content, 'html.parser')
    post_list = soup.find('ul', class_='modern-list')
    if post_list:
        post_list.clear()
        post_list.append(BeautifulSoup(posts_html, 'html.parser'))
    
    with open(sidebar_path, 'w', encoding='utf-8') as f:
        f.write(str(soup))

def process_all_markdown_files():
    """å¤„ç†æ‰€æœ‰Markdownæ–‡ä»¶"""
    md_dir = 'inner_markdown'
    posts_metadata = []
    
    for filename in os.listdir(md_dir):
        if filename.endswith('.md'):
            try:
                md_path = os.path.join(md_dir, filename)
                metadata = convert_md_to_html(md_path)
                metadata['filename'] = filename
                posts_metadata.append(metadata)
            except Exception as e:
                print(f'å¤„ç†æ–‡ä»¶ {filename} æ—¶å‡ºé”™: {str(e)}')
    
    try:
        update_sidebar(posts_metadata)
        update_featured_posts(posts_metadata)
        print('æˆåŠŸæ›´æ–°æ‰€æœ‰æ–‡ä»¶')
    except Exception as e:
        print(f'æ›´æ–°è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}')

if __name__ == '__main__':
    process_all_markdown_files()